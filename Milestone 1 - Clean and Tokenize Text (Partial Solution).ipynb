{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OeIHZdTXg03B"
   },
   "source": [
    "# Milestone 1: Clean and Tokenize Text\n",
    "The goal of this task is to to reduce the noise in the original raw text and tokenize the text to prepare it for the language maodel. We need to remove everything that is not exactly text (e.g html tags, math equations, urls, etc), filter out any rows with very short or very long texts and finally tokenize the text for use in a language model. The cleaned and tokenized output will be used as the input in the next milestone to build our n-gram model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PbiEgK7HS4L4"
   },
   "outputs": [],
   "source": [
    "# We only need the following librairies\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "import csv\n",
    "import numpy as np\n",
    "from nltk.tokenize import WordPunctTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there's a problem with the versions of the librairies, you can uncomment the line below and install the proper versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JfW0QBdig_k7"
   },
   "source": [
    "Let's load the dataset and shuffle it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YWZx8tbrVrx8"
   },
   "outputs": [],
   "source": [
    "#Load data using pandas read_csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JgzBFBwWvG3q"
   },
   "outputs": [],
   "source": [
    "#Check data has 812132 rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WyWqejm3hUE-"
   },
   "source": [
    "And start by exploring the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "colab_type": "code",
    "id": "eiMeKSHbV7Lv",
    "outputId": "bb0bd4bd-6eb9-4c98-f1f7-1a47a8ecdff4"
   },
   "outputs": [],
   "source": [
    "#Check the first few rows of the data\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Bon5CFezh_v1"
   },
   "source": [
    "We have 3 types of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "oQK2WV0JWADk",
    "outputId": "98f300dd-f186-4abb-b45c-ddaac4b59b43"
   },
   "outputs": [],
   "source": [
    "#Check the value counts for the category column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "vR-r4JgDiD5M",
    "outputId": "f08b65d9-05b0-499c-84a9-fafd45aae7e1"
   },
   "outputs": [],
   "source": [
    "#Print a few examples of titles \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iA47aMGKiSAk"
   },
   "source": [
    "We see that posts text have html tags and latex formatted equations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 658
    },
    "colab_type": "code",
    "id": "QagyZuf0iJqO",
    "outputId": "f7ecd5cf-8a19-4f5c-901e-e7a2ff847b49"
   },
   "outputs": [],
   "source": [
    "#Print a few examples of posts \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "No7lYssNiNCy",
    "outputId": "13568e3d-b64c-4d1f-904d-be913cbf2b2e"
   },
   "outputs": [],
   "source": [
    "#Print a few examples of comments \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Mk-vHb7LiZrf"
   },
   "source": [
    "# Clean up raw text\n",
    "We're going to remove the following elements:\n",
    "* html tags\n",
    "* line returns\n",
    "* urls\n",
    "* latex equations\n",
    "* numbers\n",
    "* mentions: @someone\n",
    "* digits\n",
    "* most of the punctuation\n",
    "* and extra spaces\n",
    "\n",
    "For that we will use a series of simple regex patterns and the following pandas dataframe pattern:\n",
    "\n",
    "```\n",
    "pattern = r\" some regex pattern\"\n",
    "df.text.apply(lambda t : re.sub(pattern,' ', t) )\n",
    "```\n",
    "\n",
    "Note that it's up to you to decide which elements should be removed or kept. This sequence of transformations can be modified. \n",
    "\n",
    "Not also that the regex patterns we use here are chosen for their simplicity. Feel free to use more precise patterns.  \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VAr8qzoKiQjx"
   },
   "outputs": [],
   "source": [
    "# Remove html tags\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DS_VHPC1jN5i"
   },
   "outputs": [],
   "source": [
    "# Remove line returns\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TyQeTFN9jPvK"
   },
   "outputs": [],
   "source": [
    "# Remove urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TI1vZWUFjRCT"
   },
   "outputs": [],
   "source": [
    "# Remove mentions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "29nqngCpjST2"
   },
   "outputs": [],
   "source": [
    "# Remove latex\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X2ZBG7PkjTlQ"
   },
   "outputs": [],
   "source": [
    "# Remove digits \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PEmEZVOwjVmy"
   },
   "outputs": [],
   "source": [
    "# Remove some of the punctuation but keep ,.!? and -\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DhtXc_dPjX88"
   },
   "outputs": [],
   "source": [
    "# Remove multiple spaces\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sYJyjInajZQG"
   },
   "outputs": [],
   "source": [
    "# Finally remove trailing spaces with strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nY6RQnqSjbk3"
   },
   "source": [
    "Let's check out the resulting text for the different types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "j7D5HfhXjZ8t",
    "outputId": "77b24bea-2d06-460e-dd13-ed9f66229658"
   },
   "outputs": [],
   "source": [
    "# Print examples of titles again - they should not be changed\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "_pyo6Bdhjl4J",
    "outputId": "4a185842-a6d7-4a3c-eaa0-51f86a5966f2"
   },
   "outputs": [],
   "source": [
    "# Print examples of posts again - they should have much less clutter\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 138
    },
    "colab_type": "code",
    "id": "KKeBjpmsjxjZ",
    "outputId": "7301b185-7987-4503-8f63-20a1eb715962",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Print examples of comments again - should also be less noisy\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E4T1CQqWk6rP"
   },
   "source": [
    "# Tokenize\n",
    "\n",
    "Let's tokenize the text. \n",
    "This will allow us to count the number of tokens of each text and subsequently remove test that are too long or too short.\n",
    "You can use other librairies to tokenize the text (spacy for instance) or other tokenizer. Here we use the [WordPunctTokenizer](https://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.regexp.WordPunctTokenizer) from NLTK.\n",
    "\n",
    "And we create a new columns called tokens\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2ge5LTc3j4Te"
   },
   "outputs": [],
   "source": [
    "#Create a tokenizer object using WordPunctTokenizer from NLTK \n",
    "\n",
    "#Apply the tokenizer to the text column (conver to lowercase first) and save output into new column called tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2Ll09OAjmGby"
   },
   "source": [
    "Let's now count the tokens in each piece of text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r3dp7L-Hl-AR"
   },
   "outputs": [],
   "source": [
    "#Count the number of tokens in each text and save output into new column called n_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168
    },
    "colab_type": "code",
    "id": "dzIE6rdWmPCo",
    "outputId": "40670ac8-d6c1-4909-e7fa-128630266d34"
   },
   "outputs": [],
   "source": [
    "#Describe the number of tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "colab_type": "code",
    "id": "PrwoRVQnmRa3",
    "outputId": "9b208aa6-0e3b-48d7-e15f-417e4b6536ff"
   },
   "outputs": [],
   "source": [
    "#Do a histplot to check the distribution of the number of tokens\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oJGNrR5wmV5r"
   },
   "source": [
    "We see that we have some extremely long texts. Let's look at the largest one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "SgsxoSdWmUe3",
    "outputId": "6a72f8d1-d2ac-45b7-b1c9-0e669b025187"
   },
   "outputs": [],
   "source": [
    "# Print the largest token\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nK4wiFJamvac"
   },
   "source": [
    "We can see that most of the longest texts are composed of tables with limited semantic value. \n",
    "We will remove rows that have more than an arbitrary number of tokens (let's say 5000) as well as rows that have too few tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "cw8QXJ9CmjTo",
    "outputId": "5466e0dd-77c2-45ea-bd71-796063abbbe4"
   },
   "outputs": [],
   "source": [
    "#Remove rows with less than 4 or more than 5000 tokens\n",
    "\n",
    "#Check the number of rows after filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "id": "P2IOaPeKsDHO",
    "outputId": "7a2883b6-6a39-48ac-df35-fec8290ebe4f"
   },
   "outputs": [],
   "source": [
    "#Lets check the value counts for each category again\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fe4WDsdFnQ29"
   },
   "source": [
    "# Export data\n",
    "We could export the dataframe as such using a pickle file format. \n",
    "\n",
    "However if we want to keep the original csv format it's going to be easier if we transform the list of tokens into a space separated string.\n",
    "\n",
    "On retrieval we will only have to split the string to get back the list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "vgqfut5snKj4",
    "outputId": "91673f01-cb41-45ee-f755-60a15efb3ade"
   },
   "outputs": [],
   "source": [
    "#Change tokens column to a space separated string of tokens rather a list\n",
    "\n",
    "#Check the first few rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally let's export the dataframe into a csv file.\n",
    "\n",
    "We will use that csv file as the new cleaned and tokenized dataset to build our language model in milestone 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write to csv to upload\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
